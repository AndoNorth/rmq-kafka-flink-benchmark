version: "3.8"

services:

  rabbitmq:
    image: rabbitmq:3.13.7-management
    hostname: rabbitmq
    mem_limit: 2g
    ports:
      - "5672:5672"
      - "15672:15672"
      - "5552:5552"
    environment:
      RABBITMQ_ERLANG_COOKIE: "RABBITMQCOOKIE123"
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: >
        -rabbitmq_stream advertised_host rabbitmq
        -rabbit vm_memory_high_watermark 0.6
    command: >
      bash -c "
      rabbitmq-plugins enable --offline rabbitmq_stream &&
      rabbitmq-server"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:2.13-2.8.1
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1

    depends_on:
      - zookeeper

  # Kafka topic init with SCALE_FACTOR
  kafka-init:
    image: wurstmeister/kafka:2.13-2.8.1
    depends_on:
      - kafka
    entrypoint: >
      bash -c '
        sleep 15 &&
        kafka-topics.sh --create \
          --if-not-exists \
          --topic events \
          --bootstrap-server kafka:9092 \
          --partitions '"${SCALE_FACTOR}"' \
          --replication-factor 1
        echo "Waiting for kafka topic to be ready"
        until kafka-topics.sh --bootstrap-server kafka:9092 --describe --topic events 2>/dev/null | grep -q 'PartitionCount'; do
          echo "Waiting for Kafka topic 'events'..."
          sleep 5
        done
      '

  # RabbitMQ superstream init
  rabbitmq-init:
    image: rabbitmq:3.12-management
    depends_on:
      - rabbitmq
    environment:
      RABBITMQ_ERLANG_COOKIE: "RABBITMQCOOKIE123"
    entrypoint: >
      bash -c "
        echo 'Waiting for RabbitMQ node...' &&
        until rabbitmqctl -n rabbit@rabbitmq ping 2>/dev/null; do
          echo 'RabbitMQ not ready yet...'
          sleep 5
        done &&
        echo 'Stream plugin loaded. Creating superstream...' &&
        rabbitmq-plugins enable rabbitmq_stream &&
        until rabbitmq-streams -n rabbit@rabbitmq add_super_stream events --partitions ${SCALE_FACTOR} 2>&1 | grep -E -q 'Super stream|already exists'; do
          echo 'Retrying superstream creation...'
          sleep 5
        done
        echo 'Superstream created with ${SCALE_FACTOR} partitions'
      "

  akhq:
    image: tchiotludo/akhq:0.26.0
    ports:
      - "8082:8080"
    volumes:
      - ./akhq-config.yaml:/app/application.yml
    depends_on:
      - kafka

  jobmanager:
    build: ./flink
    command: jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    volumes:
      - ./flink-jobs/kafka-job.py:/opt/flink/jobs/kafka-job.py:ro
      - ./flink-jobs/rmq-job.py:/opt/flink/jobs/rmq-job.py:ro

  taskmanager:
    build: ./flink
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=${TASK_SLOTS}
    depends_on:
      - jobmanager

  kafkaproducer:
    build: ./kafka-producer
    environment:
      - TOTAL_MESSAGES=${TOTAL_MESSAGES}
      - DURATION_SECONDS=${DURATION_SECONDS}
    depends_on:
      - kafka-init

  rabbitmqproducer:
    build: ./rabbitmq-producer
    environment:
      - TOTAL_MESSAGES=${TOTAL_MESSAGES}
      - DURATION_SECONDS=${DURATION_SECONDS}
    depends_on:
      - rabbitmq-init

  flink-job-submitter:
    build: ./flink
    depends_on:
      jobmanager:
        condition: service_started
      kafka-init:
        condition: service_completed_successfully
      rabbitmq-init:
        condition: service_completed_successfully
    environment:
      JOB_MANAGER_RPC_ADDRESS: jobmanager 
      TASKMANAGER_SCALE: ${TASKMANAGER_SCALE}
      TASK_SLOTS: ${TASK_SLOTS}
    volumes:
      - ./flink-jobs/kafka-job.py:/opt/flink/jobs/kafka-job.py:ro
      - ./flink-jobs/rmq-job.py:/opt/flink/jobs/rmq-job.py:ro
      - ./flink-jobs/flink-rmq-stream-job/target/flink-rmq-stream-job-1.0-SNAPSHOT.jar:/opt/flink/jobs/flink-rmq-stream-job.jar:ro
    entrypoint: >
      bash -c '
        echo "Waiting for JobManager..." &&
        until curl -s http://$${JOB_MANAGER_RPC_ADDRESS}:8081/overview > /dev/null; do sleep 5; done &&

        echo "Calculating slots for tm_scale=$${TASKMANAGER_SCALE} and task_slots=$${TASK_SLOTS}" &&
        TOTAL_SLOTS=$$(( $${TASKMANAGER_SCALE} * $${TASK_SLOTS} )) &&
        echo "Total slots: $${TOTAL_SLOTS}" &&
        HALF_SLOTS=$$(( $${TOTAL_SLOTS} / 2 )) &&
        echo "Half slots: $${HALF_SLOTS}" &&

        echo "Submitting Kafka job with parallelism $${HALF_SLOTS}/$${TOTAL_SLOTS}" &&
        flink run -d -m $${JOB_MANAGER_RPC_ADDRESS}:8081 -p $${HALF_SLOTS} -py /opt/flink/jobs/kafka-job.py &&

        echo "Submitting RabbitMQ job with parallelism $${HALF_SLOTS}/$${TOTAL_SLOTS}" &&
        # flink run -d -m $${JOB_MANAGER_RPC_ADDRESS}:8081 -p $${HALF_SLOTS} -py /opt/flink/jobs/rmq-job.py &&
        flink run -d -m $${JOB_MANAGER_RPC_ADDRESS}:8081 -p $${HALF_SLOTS} /opt/flink/jobs/flink-rmq-stream-job.jar &&

        echo "Done."
      '


